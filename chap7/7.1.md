# chap 7 RNN을 사용한 문장 생성  
* 언어 모델을 사용해 '문장 생성' 수행  
1. 말뭉치 사용해 새로운 문장 생성  
2. seq2seq 구조 신경망 : 한 시계열 데이터를 다른 시계열 데이터로 변환 (RNN 두개 연결)  

## 7.1 언어 모델을 사용한 문장 생성  
### 7.1.1 RNN을 사용한 문장 생성의 순서  
* 언어모델: 지금까지 주어진 단어들에서 다음에 출현하는 단어의 확률 분포 출력  
* 확률 분포 결과를 기초로 다음 단어를 새로 생성하려면?
    * 확률이 가장 높은 단어 선택  
    * '확률적' 으로 선택  : 선택되는 단어가 매번 다를 수 있다.  
    
* 이렇게 생성된 문장은 새로 생성된 문장 : 언어 모델은 훈련 데이터를 암기한 것이 아니라 훈련 데이터에서 사용된 단어의 정렬 패턴을 학습한 것  

***
# 7.1.2 문장 생성 구현   
```python
import sys
sys.path.append('..')
import numpy as np
from answer.ch06.rnnlm import Rnnlm
from answer.ch06.better_rnnlm import BetterRnnlm

def softmax(x):
    if x.ndim == 2:
        x = x - x.max(axis=1, keepdims=True)
        x = np.exp(x)
        x /= x.sum(axis=1, keepdims=True)
    elif x.ndim == 1:
        x = x - np.max(x)
        x = np.exp(x) / np.sum(np.exp(x))

    return x

class RnnlmGen(Rnnlm):
    def generate(self, start_id, skip_ids=None, sample_size=100): 
        word_ids=[start_id]
        x=start_id # 최초로 주어지는 단어 아이디
        while len(word_ids) <sample_size: # 샘플링 단어수
            x=np.array(x).reshape(1,1) # x가 2차원배열이어야 한다. -> reshape 해야 한다.
            score=self.predict(x) # 각 단계 점수 출력
            p=softmax(score.flatten()) # 정규화
            sampled=np.random.choice(len(p), size=1, p=p) # 샘플링
            if(skip_ids is None) or (sampled not in skip_ids): # skip_ids = id 리스트 : 이 리스트에 속한 id는 샘플링 안해준다. 
                x=sampled
                word_ids.append(int(x))     
        return word_ids
    

```
* np.random.choice() 메서드 사용 : 무작위 샘플링 + size 지정 + replace=False (중복 제거) + p(확률분포 담은 리스트 지정 -> 확률분포대로 샘플링)

* 아무 학습 수행하지 않은 상태에서 문장 생성  

***
### 7.1.3 더 좋은 문장으로  
* generate_better_text.py