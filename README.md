# 밑바닥부터 시작하는 딥러닝 2권
##Deep Learning from scratch2 self study
***
2021 1/4:  
* chapter1. 신경망 복습  
  * 1.1 수학과 파이썬 복습
***
2021 1/5:  
* chapter1. 신경망 복습  
  * 1.2 신경망의 추론
  * 1.3 신경망의 학습
***
2021 1/6:
* chapter1. 신경망 복습  
  * 1.4 신경망으로 문제를 풀다
  * 1.5 계산 고속화
  * 1.6 정리  
  
***  
2021 1/7:  
* chapter2. 자연어와 단어의 분산 표현  
  * 2.1 자연어 처리란  
  * 2.2 시소러스  
  * 2.3 통계 기반 기법  
  
***
2021 1/8:  
* chapter2. 자연어와 단어의 분산 표현  
  * 2.4 통계 기반 기법 개선하기  
  * 2.5 정리  
  
* chapter3. word2vec  
  * 3.1 추론 기반 기법과 신경망  
  * 3.2 단순한 word2vec  
  * 3.3 학습 데이터 준비  
  * 3.4 CBOW 모델 구현  
  * 3.5 word2vec 보충  
  * 3.6 정리  
  

***
2021 1/11:  
* chapter4. word2vec 속도 개선  
  * 4.1 word2vec 개선 1
  * 4.2 word2vec 개선 2
  
***
2021 1/12:  
* chapter4. word2vec 속도 개선
  * 4.3 개선판 word2vec 학습  
  * 4.4 word2vec 남은 주제  
  * 4.5 정리  
  
* chapter5. 순환 신경망(RNN)  
  
  * 5.1 확률과 언어 모델
  * 5.2 RNN 이란
  * 5.3 RNN 구현
  * 5.4 시계열 데이터 처리 계층 구현
  * 5.5 RNNLM 학습과 평가
  * 5.6 정리
  
***
2021 1/14:
* chapter6. 게이트가 추가된 RNN  
  * 6.1 RNN의 문제점  
  * 6.2 기울기 소실과 LSTM
  * 6.3 LSTM구현
  * 6.4 LSTM 을 사용한 언어 모델
  * 6.5 RNNLM 추가 개선  
  
***
2021 1/18:  
* chapter7 RNN을 사용한 문장 생성  
  * 7.1 언어 모델을 사용한 문장 생성  
  * 7.2 seq2seq  
  * 7.3 seq2seq 구현  
  * 7.4 seq2seq 개선  
  * 7.5 seq2seq를 이용하는 애플리케이션  
  
***
2021 1/19:  
* chapter8 어텐션  
  * 8.1 어텐션 구조  
  * 8.2 어텐션을 갖춘 seq2seq 구현  
  * 8.3 어텐션 평가
  
***
2021 1/20:
* chapter8 어텐션
  * 8.4 어텐션에 관한 남은 이야기  
  * 8.5 어텐션 응용
